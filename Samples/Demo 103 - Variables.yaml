description: >
  Demonstrate taking advantage of variables set in the UI. This includes user-
  defined variables, as well as default values for variables.
version: 1
### ============= STANDARD PRE-PROCESSING =============
# SETUP run context, and skip duplicate CREATE vt_* statements :
{% set run = namespace(completed=[], dates=[]) if run is not defined else run %}
### import macro to harden start/end dates:
{% import "coa_util.j2" as macro with context %}
{{ macro.harden_dates(run, startdate, enddate) }}
{% set startdate = run.dates[0] %}
{% set enddate = run.dates[1] %}
### ============= STANDARD PRE-PROCESSING =============


tasks:

# variables appear in double curly-brackets, and can substitute any part
# of the configuration.  For example, below we place the variable siteid
# (aka site_id of the source system) into the SQL, in the filename, and
# in the description:
- name: Export contents of dbc.info for {{ siteid }}
  connect: source
  export:
    file: {{ siteid }}_dbcinfo.csv
    sql: |
      Select '{{ siteid }}' as Site_ID
      ,info.*
      from dbc.dbcinfo as info

# All of these substitutions are completed when you "explain" the process,
# meaning you'll always see the completed SQL prior to execution.

# if you have parameters that are required, you can supply a default
# so the sql will always run, even if user doesn't fill in a value
- name: Export all dates for supplied month_of_calendar
  connect: source
  export:
    file: {{ siteid }}_dates.csv
    sql: |
      select
       calendar_date as LogDate
      ,month_of_calendar
      from sys_calendar.calendar
      where month_of_calendar = {{ demo_month_of_calendar | default('1234') }}
      order by LogDate
# user can now supply demo_month_of_calendar, or if omitted, a default will apply


# there are some built-in variables available, with the prefix: "dbc" that will
# return different values depending on the collection type of the source system,
# aka pdcr or dbc.   For exmaple, the SQL below will return the first 10 rows
# from the QueryLog table, auto-selecting either dbc.dbqlogtbl or
# pdcrinfo.dbqlogtbl_hst.   It will also auto-select the correct column for
# LogDate, depending on the collection type.
- name: Export top 10 records from either pdcr or dbc querylog table
  connect: source
  export:
    file: dbql_first10_rows.csv
    sql: |
      select top 10 *
      from {{ dbc.log }} as qrylog
      where {{ dbc.logdt }} = DATE-1
# there are 20 translated tables (DBQL, ResUsage), and we can continue to extend
# as it makes sense.  A full list can be found in the "Collaboration" section of
# the sharepoint documentation: https://teradata.sharepoint.com/teams/SalesTech/COA


# finally, you can set variables in code, with defaults, and allow the user to
# override (or not).  This is frequently used for "hidden" variables that
# modify the behavior of the process.  Some common examples:
#      variable     default if variable   is not defined otherwise use what WAS defined
{% set chart      = True    if chart      is not defined else chart %}
{% set upload     = False   if upload     is not defined else upload %}
{% set export_all = False   if export_all is not defined else export_all %}
{% set reconcile  = False   if reconcile  is not defined else reconcile %}

# the above variables are all boolean, but don't have to be:
{% set year  = 2021  if year  is not defined else year %}
{% set stage = 'dev' if stage is not defined else stage %}

# to use these variables:
- name: Create vt_random table (by date)
  connect: source
  execute:
    sql: |
      create volatile table vt_random as
      (
        select
         calendar_date as LogDate
        ,'{{ stage }}' as Stage
        ,Week_of_Year as WeekID
        ,random(10,100) as random_value1
        ,random_value1 + random(-10,30) as random_value2
        from sys_calendar.calendar
        where year_of_Calendar = {{ year }}
      ) with data no primary index on commit preserve rows

# note that year didn't have a default defined in the SQL, as it was
# predefined above instead.

{% if chart %}
# anything inside this IF only happens if "chart" is True
# per above, the default behavior (if not overridden by user) is TRUE

- name: Export random number by week, for charting
  connect: source
  export:
    file: random_week_for_charting.csv
    sql: |
      select
       max(LogDate) as "Week Beginning"
      ,sum(Random_Value1) as Random1
      ,sum(Random_Value2) as Random2
      from vt_random
      group by WeekID
      order by 1


- name: Chart random number by date
  chart:
    command: chart/line_xDate_yElse.py
    params:
      - "file:random_week_for_charting.csv"
      - "title:Random Number by Week - for Site: {{ siteid }}"
      - "height:6"
      - "width:12"

{% endif %}



{% if export_all %}
# anything inside this IF only happens if "export_all" is True
# per above, the default behavior (if not overridden by user) is FALSE
# to make this code execute, make a new variable called "export_all" = True

- name: Export entire vt_random
  connect: source
  export:
    file: random_date.csv
    sql: select *  from vt_random order by 1

{% endif %}



{% if stage == 'prod' %}
# anything inside this section only happens if stage is 'prod'

- name: Export data for prod data
  connect: source
  export:
    file: random_stage_prod.csv
    sql: |
      select stage, 'this is only for prod purposes' as msg
      ,sum(Random_Value1) as Random1
      from vt_random
      group by stage



{% elif stage == 'dev' %}
# anything inside this section only happens if stage is 'dev'

- name: Export data for dev data
  connect: source
  export:
    file: random_stage_dev.csv
    sql: |
      select stage, 'this is only for dev purposes' as msg
      ,sum(Random_Value1) as Random1
      from vt_random
      group by stage



{% else %}
# this section will execute if stage is not 'dev' nor 'prod'

- name: Export data for unknown stage data
  connect: source
  export:
    file: random_stage_unknown.csv
    sql: |
      select stage, 'this stage is not recongized: {{ stage }}' as msg
      ,sum(Random_Value1) as Random1
      from vt_random
      group by stage

{% endif%}




# A more elegent alternative to do the above test:
# (the tilde character ~ is for string concatination)
{% if stage in ['prod','dev'] %}
{% set msg = 'this is only for ' ~ stage ~ ' purposes' %}
{% else %}
{% set msg = 'this stage is not recongized: ' ~ stage %}
{% set is_unknown = True %}
{% endif %}

- name: Export data for {{ 'unknown stage' if is_unknown else stage }} data (alt)
  connect: source
  export:
    file: random_stage_{{ 'unknown' if is_unknown else stage }}_alt.csv
    sql: |
      select stage, '{{ msg }}' as msg
      ,sum(Random_Value1) as Random1
      from vt_random
      group by stage

# this approach honors the jinja precept: don't repeat yourself (DRY)
# this way, one change covers all 3 scenarios: Dev, Prod, and Unknown




# you can also test to see if a string is inside a variable.  This allows you
# to manage one variable, then test for sub-components.  For example:

# set default
{% set include_time = 'Week,Month,Quarter,Year' if include_time is not defined else include_time %}

# setup collection table
- name: "Create vt_time_period for collection"
  connect: source
  execute:
    sql: |
      create volatile table vt_time_selection
      (order_created      integer
      ,selected_with      varchar(128)
      ,time_period        varchar(128)
      ,full_include_txt   varchar(128)
      ,insert_ts          timestamp(0)
      ) no primary index
        on commit preserve rows

# TEST if include_time contains Quarter
{% if 'Quarter' in include_time %}
- name: "Insert time_period: quarter"
  connect: source
  execute:
    sql: |
      insert into vt_time_selection( 1
       ,'hard-coded search for "Quarter"'
       ,'Quarter'
       ,'{{ include_time }}'
       ,current_timestamp(0))
{% endif %}

# note, the above test is CAP SENSITIVE, so this NEAR identical block
# will never run:
{% if 'quarter' in include_time %}  # only difference is lower-case "q"
- name: "Insert time_period: quarter"
  connect: source
  execute:
    sql: |
      insert into vt_time_selection( 2
       ,'doesn''t matter, this will never run'
       ,'Quarter'
       ,'{{ include_time }}'
       ,current_timestamp(0))
{% endif %}

# to correct for Cap sensitivity, you can cast strings to all lower case:
{% if 'quarter' in include_time.lower() %}  # now everything is lower-case
- name: "Insert time_period: Quarter (with .lower())"
  connect: source
  execute:
    sql: |
      insert into vt_time_selection( 3
       ,'hard-coded search for "Quarter", with lower (#2 was not run because of Cap Sensitivity)'
       ,'Quarter'
       ,'{{ include_time }}'
       ,current_timestamp(0))
{% endif %}

# Advanced: we can also split the include_time by comma, and loop thru each time:
{% set times = include_time.split(',') %}
{% for time in times %}
- name: "Insert time_period: {{ time }}"
  connect: source
  execute:
    sql: |
      insert into vt_time_selection( 3 + {{loop.index}}
       ,'iterative for loop on "{{ time }}"'
       ,'{{ time }}'
       ,'{{ include_time }}'
       ,current_timestamp(0))
{% endfor %}
# the loop.index is a Jinja internal counter of interation count.  we can use
# it to continue incrementing our counter without defining another variable

# export results
- name: Export entire vt_time_selection
  connect: source
  export:
    file: time_selection.csv
    sql: select *  from vt_time_selection order by 1
